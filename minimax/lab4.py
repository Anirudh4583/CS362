# -*- coding: utf-8 -*-
"""lab4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Y66Ig4CbhTuuBR2Rb8iHjc-_xzdblh5
"""

import numpy as np
import math

def updateCurrentState(currentState,move,position):
  # this func will return updated state
  state=currentState.copy()
  state[position]=move
  return state

# Check if Player 1 wins return +10
# Check if Player 2 wins return -10
# Check if it is draw return 0
# otherwise return -1

def isGameOver(currentState,evaluatedNodes):
  state=currentState.copy()

  # check for Horizontal win
  for i in range(0,7,3) :
    if (state[i] == state[i + 1] == state[i + 2]):
      if (state[i]=='X'):
        return 10,evaluatedNodes+1
      elif (state[i]=='O'):
        return -10,evaluatedNodes+1

  # check vertical win
  for i in range(0,3):
    if (state[i] == state[i + 3] == state[i + 6]):
      if (state[i]=='X'):
        return 10,evaluatedNodes+1
      elif (state[i]=='O'):
        return -10,evaluatedNodes+1

  #check diagonal win
  if (state[0] == state[4] == state[8]) :
    if (state[0]=='X'):
        return 10,evaluatedNodes+1
    elif (state[0]=='O'):
        return -10,evaluatedNodes+1
  if (state[2] == state[4] == state[6]):
    if ( state[2]=='X'):
        return 10,evaluatedNodes+1
    elif (state[2]=='O'):
        return -10,evaluatedNodes+1

  # Check if it is a draw
  if len(getEmptySpaces(state)) == 0:
    return 0,evaluatedNodes+1

  return -1,evaluatedNodes+1

def getEmptySpaces(currentState):
  count=[]
  for i in range(len(currentState)):
    if currentState[i] == ' ':
      count.append(i)
  return np.array(count)

def minmax(depth ,maximizingPlay ,currentState,parentIndex,evaluatedNodes):
  move = 'X' if maximizingPlay else 'O'
  moveScore,evaluatedNodes=isGameOver(currentState,evaluatedNodes)
  # if moveScore == 10 or moveScore==-10 :
  #   print(currentState.reshape(3,3))
  if depth == 0 or moveScore != -1:
    # return some static value 
    return [moveScore,currentState,evaluatedNodes]
  # Player 1's move
  if maximizingPlay :
    maxEval = -math.inf
    # get empty indices from the current state
    emptyIndices=getEmptySpaces(currentState)
    best = None
    for i in emptyIndices:
      updatedState = updateCurrentState(currentState,move,i)
      eval,bestTemp,evaluatedNodes=minmax(depth-1,False,updatedState,i,evaluatedNodes)
      maxEval=max(maxEval,eval)
      best = bestTemp if maxEval == eval else best
    return [maxEval,best,evaluatedNodes]
  else:
    minEval = math.inf
    # get empty indices from the current state
    emptyIndices=getEmptySpaces(currentState)
    best = None
    for i in emptyIndices:
      updatedState = updateCurrentState(currentState,move,i)
      eval,bestTemp,evaluatedNodes=minmax(depth-1,True,updatedState,i,evaluatedNodes)
      minEval=min(minEval,eval)
      best = bestTemp if minEval == eval else best
    return [minEval,best,evaluatedNodes]

def alphaBetaPruning(depth ,maximizingPlay,alpha,beta ,currentState,parentNode,evaluatedNodes):
  move = 'X' if maximizingPlay else 'O'
  moveScore,evaluatedNodes=isGameOver(currentState,evaluatedNodes)
  # if moveScore == 10 or moveScore==-10 :
  #   print(currentState.reshape(3,3))
  if depth == 0 or moveScore != -1:
    # return some static value 
    return [moveScore,evaluatedNodes]
  # Player 1's move
  if maximizingPlay :
    maxEval = -math.inf
    # get empty indices from the current state
    emptyIndices=getEmptySpaces(currentState)
    for i in emptyIndices:
      updatedState = updateCurrentState(currentState,move,i)
      eval,evaluatedNodes=alphaBetaPruning(depth-1,False,alpha,beta ,updatedState,i,evaluatedNodes)
      maxEval=max(maxEval,eval)
      alpha=max(alpha,eval)
      if (beta<=alpha):
        break
    return [maxEval,evaluatedNodes]
  else:
    minEval = math.inf
    # get empty indices from the current state
    emptyIndices=getEmptySpaces(currentState)
    for i in emptyIndices:
      updatedState = updateCurrentState(currentState,move,i)
      eval,evaluatedNodes=alphaBetaPruning(depth-1,True,alpha,beta ,updatedState,i,evaluatedNodes)
      minEval=min(minEval,eval)
      beta=min(beta,eval)
      if (beta<=alpha):
        break
    return [minEval,evaluatedNodes]

InitialState=np.array([' ',' ',' ',' ',' ',' ',' ',' ',' '])

points,board,evaluatedNodes=minmax(9,True,InitialState,None,0)

pointABP,evaluatedNodesABP=alphaBetaPruning(9,True,-math.inf,math.inf,InitialState,None,0)
print("Minimax : ")
print(points,board.reshape(3,3),"\n Evaluated Nodes = ",evaluatedNodes)
print("Alpha Beta Pruining : ")
print(pointABP,"\n Evaluated Nodes = ",evaluatedNodesABP)